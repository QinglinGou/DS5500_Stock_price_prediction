{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df7a4b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "from sklearn.multioutput import MultiOutputRegressor, RegressorChain\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from boruta import BorutaPy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01db1fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Data_intergate(y, pday):\n",
    "    y = np.array(y)\n",
    "    y_process = []\n",
    "    for i in range(y.shape[0]):\n",
    "        if i + pday < y.shape[0]:\n",
    "            Tmp_y = np.array([])\n",
    "            for p in range(pday):\n",
    "                Tmp_y = np.append(Tmp_y, y[i+p+1])\n",
    "            y_process.append(Tmp_y)\n",
    "    y_process = np.array(y_process)\n",
    "    return y_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f9c2fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>MOM_5</th>\n",
       "      <th>MOM_10</th>\n",
       "      <th>MOM_14</th>\n",
       "      <th>STCK</th>\n",
       "      <th>STCD</th>\n",
       "      <th>close_5_sma</th>\n",
       "      <th>close_5_ema</th>\n",
       "      <th>close_10_sma</th>\n",
       "      <th>...</th>\n",
       "      <th>macd_45_25_15</th>\n",
       "      <th>rsi_14</th>\n",
       "      <th>rsi_28</th>\n",
       "      <th>wr_14</th>\n",
       "      <th>wr_28</th>\n",
       "      <th>wr_50</th>\n",
       "      <th>wr_100</th>\n",
       "      <th>cci_14</th>\n",
       "      <th>cci_50</th>\n",
       "      <th>cci_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>21.368668</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.368668</td>\n",
       "      <td>21.368668</td>\n",
       "      <td>21.368668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-14.221371</td>\n",
       "      <td>-14.221371</td>\n",
       "      <td>-14.221371</td>\n",
       "      <td>-14.221371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>21.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.259334</td>\n",
       "      <td>21.237467</td>\n",
       "      <td>21.259334</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-56.140329</td>\n",
       "      <td>-56.140329</td>\n",
       "      <td>-56.140329</td>\n",
       "      <td>-56.140329</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>20.974667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.164445</td>\n",
       "      <td>21.112983</td>\n",
       "      <td>21.164445</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-54.317817</td>\n",
       "      <td>-54.317817</td>\n",
       "      <td>-54.317817</td>\n",
       "      <td>-54.317817</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>21.105333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.149667</td>\n",
       "      <td>21.109805</td>\n",
       "      <td>21.149667</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009769</td>\n",
       "      <td>27.107971</td>\n",
       "      <td>25.973986</td>\n",
       "      <td>-44.302518</td>\n",
       "      <td>-44.302518</td>\n",
       "      <td>-44.302518</td>\n",
       "      <td>-44.302518</td>\n",
       "      <td>-32.272842</td>\n",
       "      <td>-32.272842</td>\n",
       "      <td>-32.272842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>22.427334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.405200</td>\n",
       "      <td>21.615586</td>\n",
       "      <td>21.405200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044085</td>\n",
       "      <td>81.563100</td>\n",
       "      <td>80.128434</td>\n",
       "      <td>-1.946364</td>\n",
       "      <td>-1.946364</td>\n",
       "      <td>-1.946364</td>\n",
       "      <td>-1.946364</td>\n",
       "      <td>161.635945</td>\n",
       "      <td>161.635945</td>\n",
       "      <td>161.635945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>2024-04-10</td>\n",
       "      <td>171.759995</td>\n",
       "      <td>3.379990</td>\n",
       "      <td>-5.910003</td>\n",
       "      <td>-3.900009</td>\n",
       "      <td>47.388364</td>\n",
       "      <td>56.290371</td>\n",
       "      <td>171.525998</td>\n",
       "      <td>172.288693</td>\n",
       "      <td>172.348000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.535005</td>\n",
       "      <td>45.856141</td>\n",
       "      <td>43.548113</td>\n",
       "      <td>-52.611636</td>\n",
       "      <td>-74.437633</td>\n",
       "      <td>-75.049906</td>\n",
       "      <td>-89.246799</td>\n",
       "      <td>-6.560040</td>\n",
       "      <td>-69.304516</td>\n",
       "      <td>-88.062685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>174.600006</td>\n",
       "      <td>3.490005</td>\n",
       "      <td>-5.229996</td>\n",
       "      <td>1.779999</td>\n",
       "      <td>59.351340</td>\n",
       "      <td>58.565027</td>\n",
       "      <td>172.223999</td>\n",
       "      <td>173.059131</td>\n",
       "      <td>171.825000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.107128</td>\n",
       "      <td>48.477531</td>\n",
       "      <td>44.907334</td>\n",
       "      <td>-40.648660</td>\n",
       "      <td>-64.092739</td>\n",
       "      <td>-68.751369</td>\n",
       "      <td>-86.532203</td>\n",
       "      <td>9.834233</td>\n",
       "      <td>-61.828807</td>\n",
       "      <td>-84.642709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>2024-04-12</td>\n",
       "      <td>171.050003</td>\n",
       "      <td>6.150009</td>\n",
       "      <td>-4.739990</td>\n",
       "      <td>0.220001</td>\n",
       "      <td>44.397665</td>\n",
       "      <td>50.379123</td>\n",
       "      <td>173.454001</td>\n",
       "      <td>172.389421</td>\n",
       "      <td>171.351001</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.019679</td>\n",
       "      <td>45.511363</td>\n",
       "      <td>43.548132</td>\n",
       "      <td>-55.602335</td>\n",
       "      <td>-56.229204</td>\n",
       "      <td>-76.624517</td>\n",
       "      <td>-89.925438</td>\n",
       "      <td>-18.526388</td>\n",
       "      <td>-68.014469</td>\n",
       "      <td>-86.079047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>161.479996</td>\n",
       "      <td>-11.500000</td>\n",
       "      <td>-13.740005</td>\n",
       "      <td>-11.150009</td>\n",
       "      <td>4.085934</td>\n",
       "      <td>35.944980</td>\n",
       "      <td>171.154001</td>\n",
       "      <td>168.752946</td>\n",
       "      <td>169.977001</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.680172</td>\n",
       "      <td>38.646476</td>\n",
       "      <td>40.150793</td>\n",
       "      <td>-95.914066</td>\n",
       "      <td>-95.914066</td>\n",
       "      <td>-97.848745</td>\n",
       "      <td>-99.072834</td>\n",
       "      <td>-133.862469</td>\n",
       "      <td>-112.860782</td>\n",
       "      <td>-101.627330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>2024-04-16</td>\n",
       "      <td>157.110001</td>\n",
       "      <td>-19.770004</td>\n",
       "      <td>-9.520004</td>\n",
       "      <td>-20.559997</td>\n",
       "      <td>11.931820</td>\n",
       "      <td>20.138473</td>\n",
       "      <td>167.200000</td>\n",
       "      <td>164.871965</td>\n",
       "      <td>169.025000</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.504317</td>\n",
       "      <td>35.977768</td>\n",
       "      <td>38.720347</td>\n",
       "      <td>-88.068180</td>\n",
       "      <td>-88.983603</td>\n",
       "      <td>-93.519767</td>\n",
       "      <td>-96.983300</td>\n",
       "      <td>-198.360579</td>\n",
       "      <td>-159.732090</td>\n",
       "      <td>-119.014012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1582 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       Close      MOM_5     MOM_10     MOM_14       STCK  \\\n",
       "0    2018-01-02   21.368668   0.000000   0.000000   0.000000   0.000000   \n",
       "1    2018-01-03   21.150000   0.000000   0.000000   0.000000   0.000000   \n",
       "2    2018-01-04   20.974667   0.000000   0.000000   0.000000   0.000000   \n",
       "3    2018-01-05   21.105333   0.000000   0.000000   0.000000   0.000000   \n",
       "4    2018-01-08   22.427334   0.000000   0.000000   0.000000   0.000000   \n",
       "...         ...         ...        ...        ...        ...        ...   \n",
       "1577 2024-04-10  171.759995   3.379990  -5.910003  -3.900009  47.388364   \n",
       "1578 2024-04-11  174.600006   3.490005  -5.229996   1.779999  59.351340   \n",
       "1579 2024-04-12  171.050003   6.150009  -4.739990   0.220001  44.397665   \n",
       "1580 2024-04-15  161.479996 -11.500000 -13.740005 -11.150009   4.085934   \n",
       "1581 2024-04-16  157.110001 -19.770004  -9.520004 -20.559997  11.931820   \n",
       "\n",
       "           STCD  close_5_sma  close_5_ema  close_10_sma  ...  macd_45_25_15  \\\n",
       "0      0.000000    21.368668    21.368668     21.368668  ...       0.000000   \n",
       "1      0.000000    21.259334    21.237467     21.259334  ...      -0.004906   \n",
       "2      0.000000    21.164445    21.112983     21.164445  ...      -0.011688   \n",
       "3      0.000000    21.149667    21.109805     21.149667  ...      -0.009769   \n",
       "4      0.000000    21.405200    21.615586     21.405200  ...       0.044085   \n",
       "...         ...          ...          ...           ...  ...            ...   \n",
       "1577  56.290371   171.525998   172.288693    172.348000  ...      -3.535005   \n",
       "1578  58.565027   172.223999   173.059131    171.825000  ...      -3.107128   \n",
       "1579  50.379123   173.454001   172.389421    171.351001  ...      -3.019679   \n",
       "1580  35.944980   171.154001   168.752946    169.977001  ...      -3.680172   \n",
       "1581  20.138473   167.200000   164.871965    169.025000  ...      -4.504317   \n",
       "\n",
       "         rsi_14     rsi_28      wr_14      wr_28      wr_50     wr_100  \\\n",
       "0      0.000000   0.000000 -14.221371 -14.221371 -14.221371 -14.221371   \n",
       "1      0.000000   0.000000 -56.140329 -56.140329 -56.140329 -56.140329   \n",
       "2      0.000000   0.000000 -54.317817 -54.317817 -54.317817 -54.317817   \n",
       "3     27.107971  25.973986 -44.302518 -44.302518 -44.302518 -44.302518   \n",
       "4     81.563100  80.128434  -1.946364  -1.946364  -1.946364  -1.946364   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1577  45.856141  43.548113 -52.611636 -74.437633 -75.049906 -89.246799   \n",
       "1578  48.477531  44.907334 -40.648660 -64.092739 -68.751369 -86.532203   \n",
       "1579  45.511363  43.548132 -55.602335 -56.229204 -76.624517 -89.925438   \n",
       "1580  38.646476  40.150793 -95.914066 -95.914066 -97.848745 -99.072834   \n",
       "1581  35.977768  38.720347 -88.068180 -88.983603 -93.519767 -96.983300   \n",
       "\n",
       "          cci_14      cci_50     cci_100  \n",
       "0       0.000000    0.000000    0.000000  \n",
       "1      66.666667   66.666667   66.666667  \n",
       "2    -100.000000 -100.000000 -100.000000  \n",
       "3     -32.272842  -32.272842  -32.272842  \n",
       "4     161.635945  161.635945  161.635945  \n",
       "...          ...         ...         ...  \n",
       "1577   -6.560040  -69.304516  -88.062685  \n",
       "1578    9.834233  -61.828807  -84.642709  \n",
       "1579  -18.526388  -68.014469  -86.079047  \n",
       "1580 -133.862469 -112.860782 -101.627330  \n",
       "1581 -198.360579 -159.732090 -119.014012  \n",
       "\n",
       "[1582 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming 'df' is your DataFrame and the 'Date' column is already in datetime format\n",
    "data = pd.read_csv(\"data/TSLA_process.csv\")\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "# Filter the DataFrame to include only records after January 1st, 2018\n",
    "data= data[data['Date'] > '2017-12-31']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20426c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>MOM_5</th>\n",
       "      <th>MOM_10</th>\n",
       "      <th>MOM_14</th>\n",
       "      <th>STCK</th>\n",
       "      <th>STCD</th>\n",
       "      <th>close_5_sma</th>\n",
       "      <th>close_5_ema</th>\n",
       "      <th>close_10_sma</th>\n",
       "      <th>...</th>\n",
       "      <th>macd_45_25_15</th>\n",
       "      <th>rsi_14</th>\n",
       "      <th>rsi_28</th>\n",
       "      <th>wr_14</th>\n",
       "      <th>wr_28</th>\n",
       "      <th>wr_50</th>\n",
       "      <th>wr_100</th>\n",
       "      <th>cci_14</th>\n",
       "      <th>cci_50</th>\n",
       "      <th>cci_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>21.368668</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.368668</td>\n",
       "      <td>21.368668</td>\n",
       "      <td>21.368668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-14.221371</td>\n",
       "      <td>-14.221371</td>\n",
       "      <td>-14.221371</td>\n",
       "      <td>-14.221371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>21.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.259334</td>\n",
       "      <td>21.237467</td>\n",
       "      <td>21.259334</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-56.140329</td>\n",
       "      <td>-56.140329</td>\n",
       "      <td>-56.140329</td>\n",
       "      <td>-56.140329</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>20.974667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.164445</td>\n",
       "      <td>21.112983</td>\n",
       "      <td>21.164445</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-54.317817</td>\n",
       "      <td>-54.317817</td>\n",
       "      <td>-54.317817</td>\n",
       "      <td>-54.317817</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>21.105333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.149667</td>\n",
       "      <td>21.109805</td>\n",
       "      <td>21.149667</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009769</td>\n",
       "      <td>27.107971</td>\n",
       "      <td>25.973986</td>\n",
       "      <td>-44.302518</td>\n",
       "      <td>-44.302518</td>\n",
       "      <td>-44.302518</td>\n",
       "      <td>-44.302518</td>\n",
       "      <td>-32.272842</td>\n",
       "      <td>-32.272842</td>\n",
       "      <td>-32.272842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>22.427334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.405200</td>\n",
       "      <td>21.615586</td>\n",
       "      <td>21.405200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044085</td>\n",
       "      <td>81.563100</td>\n",
       "      <td>80.128434</td>\n",
       "      <td>-1.946364</td>\n",
       "      <td>-1.946364</td>\n",
       "      <td>-1.946364</td>\n",
       "      <td>-1.946364</td>\n",
       "      <td>161.635945</td>\n",
       "      <td>161.635945</td>\n",
       "      <td>161.635945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>2022-12-23</td>\n",
       "      <td>123.150002</td>\n",
       "      <td>-27.079994</td>\n",
       "      <td>-55.900001</td>\n",
       "      <td>-59.299995</td>\n",
       "      <td>3.400934</td>\n",
       "      <td>3.553951</td>\n",
       "      <td>134.748001</td>\n",
       "      <td>133.682446</td>\n",
       "      <td>146.721001</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.244768</td>\n",
       "      <td>19.819924</td>\n",
       "      <td>28.777794</td>\n",
       "      <td>-96.599066</td>\n",
       "      <td>-97.330821</td>\n",
       "      <td>-98.169784</td>\n",
       "      <td>-98.900056</td>\n",
       "      <td>-145.701825</td>\n",
       "      <td>-202.095316</td>\n",
       "      <td>-154.484319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>109.099998</td>\n",
       "      <td>-40.769997</td>\n",
       "      <td>-58.720009</td>\n",
       "      <td>-70.720009</td>\n",
       "      <td>0.461074</td>\n",
       "      <td>2.779871</td>\n",
       "      <td>126.594002</td>\n",
       "      <td>125.488297</td>\n",
       "      <td>140.849000</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.072995</td>\n",
       "      <td>16.564126</td>\n",
       "      <td>26.425724</td>\n",
       "      <td>-99.538926</td>\n",
       "      <td>-99.622897</td>\n",
       "      <td>-99.735700</td>\n",
       "      <td>-99.834879</td>\n",
       "      <td>-158.019867</td>\n",
       "      <td>-222.353298</td>\n",
       "      <td>-167.374557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>112.709999</td>\n",
       "      <td>-25.090004</td>\n",
       "      <td>-48.239998</td>\n",
       "      <td>-61.329994</td>\n",
       "      <td>6.019393</td>\n",
       "      <td>3.293800</td>\n",
       "      <td>121.576001</td>\n",
       "      <td>121.228864</td>\n",
       "      <td>136.025000</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.000032</td>\n",
       "      <td>20.191722</td>\n",
       "      <td>27.993873</td>\n",
       "      <td>-93.980607</td>\n",
       "      <td>-95.070577</td>\n",
       "      <td>-96.539175</td>\n",
       "      <td>-97.834582</td>\n",
       "      <td>-128.234456</td>\n",
       "      <td>-208.780889</td>\n",
       "      <td>-163.807645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>121.820000</td>\n",
       "      <td>-15.750007</td>\n",
       "      <td>-34.980003</td>\n",
       "      <td>-51.620002</td>\n",
       "      <td>18.287102</td>\n",
       "      <td>8.255856</td>\n",
       "      <td>118.425999</td>\n",
       "      <td>121.425909</td>\n",
       "      <td>132.527000</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.771700</td>\n",
       "      <td>28.625202</td>\n",
       "      <td>31.798073</td>\n",
       "      <td>-81.712898</td>\n",
       "      <td>-85.024259</td>\n",
       "      <td>-89.485907</td>\n",
       "      <td>-93.421391</td>\n",
       "      <td>-82.891079</td>\n",
       "      <td>-173.467434</td>\n",
       "      <td>-148.892811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>123.180000</td>\n",
       "      <td>-2.169998</td>\n",
       "      <td>-34.489998</td>\n",
       "      <td>-55.870003</td>\n",
       "      <td>21.611461</td>\n",
       "      <td>15.305985</td>\n",
       "      <td>117.992000</td>\n",
       "      <td>122.010606</td>\n",
       "      <td>129.078000</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.258998</td>\n",
       "      <td>29.817521</td>\n",
       "      <td>32.351382</td>\n",
       "      <td>-78.388539</td>\n",
       "      <td>-83.524479</td>\n",
       "      <td>-88.432949</td>\n",
       "      <td>-92.762562</td>\n",
       "      <td>-67.591754</td>\n",
       "      <td>-159.130081</td>\n",
       "      <td>-143.848633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1259 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       Close      MOM_5     MOM_10     MOM_14       STCK  \\\n",
       "0    2018-01-02   21.368668   0.000000   0.000000   0.000000   0.000000   \n",
       "1    2018-01-03   21.150000   0.000000   0.000000   0.000000   0.000000   \n",
       "2    2018-01-04   20.974667   0.000000   0.000000   0.000000   0.000000   \n",
       "3    2018-01-05   21.105333   0.000000   0.000000   0.000000   0.000000   \n",
       "4    2018-01-08   22.427334   0.000000   0.000000   0.000000   0.000000   \n",
       "...         ...         ...        ...        ...        ...        ...   \n",
       "1254 2022-12-23  123.150002 -27.079994 -55.900001 -59.299995   3.400934   \n",
       "1255 2022-12-27  109.099998 -40.769997 -58.720009 -70.720009   0.461074   \n",
       "1256 2022-12-28  112.709999 -25.090004 -48.239998 -61.329994   6.019393   \n",
       "1257 2022-12-29  121.820000 -15.750007 -34.980003 -51.620002  18.287102   \n",
       "1258 2022-12-30  123.180000  -2.169998 -34.489998 -55.870003  21.611461   \n",
       "\n",
       "           STCD  close_5_sma  close_5_ema  close_10_sma  ...  macd_45_25_15  \\\n",
       "0      0.000000    21.368668    21.368668     21.368668  ...       0.000000   \n",
       "1      0.000000    21.259334    21.237467     21.259334  ...      -0.004906   \n",
       "2      0.000000    21.164445    21.112983     21.164445  ...      -0.011688   \n",
       "3      0.000000    21.149667    21.109805     21.149667  ...      -0.009769   \n",
       "4      0.000000    21.405200    21.615586     21.405200  ...       0.044085   \n",
       "...         ...          ...          ...           ...  ...            ...   \n",
       "1254   3.553951   134.748001   133.682446    146.721001  ...     -17.244768   \n",
       "1255   2.779871   126.594002   125.488297    140.849000  ...     -19.072995   \n",
       "1256   3.293800   121.576001   121.228864    136.025000  ...     -20.000032   \n",
       "1257   8.255856   118.425999   121.425909    132.527000  ...     -19.771700   \n",
       "1258  15.305985   117.992000   122.010606    129.078000  ...     -19.258998   \n",
       "\n",
       "         rsi_14     rsi_28      wr_14      wr_28      wr_50     wr_100  \\\n",
       "0      0.000000   0.000000 -14.221371 -14.221371 -14.221371 -14.221371   \n",
       "1      0.000000   0.000000 -56.140329 -56.140329 -56.140329 -56.140329   \n",
       "2      0.000000   0.000000 -54.317817 -54.317817 -54.317817 -54.317817   \n",
       "3     27.107971  25.973986 -44.302518 -44.302518 -44.302518 -44.302518   \n",
       "4     81.563100  80.128434  -1.946364  -1.946364  -1.946364  -1.946364   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1254  19.819924  28.777794 -96.599066 -97.330821 -98.169784 -98.900056   \n",
       "1255  16.564126  26.425724 -99.538926 -99.622897 -99.735700 -99.834879   \n",
       "1256  20.191722  27.993873 -93.980607 -95.070577 -96.539175 -97.834582   \n",
       "1257  28.625202  31.798073 -81.712898 -85.024259 -89.485907 -93.421391   \n",
       "1258  29.817521  32.351382 -78.388539 -83.524479 -88.432949 -92.762562   \n",
       "\n",
       "          cci_14      cci_50     cci_100  \n",
       "0       0.000000    0.000000    0.000000  \n",
       "1      66.666667   66.666667   66.666667  \n",
       "2    -100.000000 -100.000000 -100.000000  \n",
       "3     -32.272842  -32.272842  -32.272842  \n",
       "4     161.635945  161.635945  161.635945  \n",
       "...          ...         ...         ...  \n",
       "1254 -145.701825 -202.095316 -154.484319  \n",
       "1255 -158.019867 -222.353298 -167.374557  \n",
       "1256 -128.234456 -208.780889 -163.807645  \n",
       "1257  -82.891079 -173.467434 -148.892811  \n",
       "1258  -67.591754 -159.130081 -143.848633  \n",
       "\n",
       "[1259 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_days = 1\n",
    "# Load Data\n",
    "\n",
    "X_train = data[(data['Date'] > '2017-12-31')& (data['Date'] < '2023-01-01')]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b84d1dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 21.15    ],\n",
       "       [ 20.974667],\n",
       "       [ 21.105333],\n",
       "       ...,\n",
       "       [121.82    ],\n",
       "       [123.18    ],\n",
       "       [108.099998]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"data/TSLA_process.csv\")\n",
    "y_train = Data_intergate(data1['Close'][0:1260], next_days)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4040ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1259"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebf89a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>MOM_5</th>\n",
       "      <th>MOM_10</th>\n",
       "      <th>MOM_14</th>\n",
       "      <th>STCK</th>\n",
       "      <th>STCD</th>\n",
       "      <th>close_5_sma</th>\n",
       "      <th>close_5_ema</th>\n",
       "      <th>close_10_sma</th>\n",
       "      <th>...</th>\n",
       "      <th>macd_45_25_15</th>\n",
       "      <th>rsi_14</th>\n",
       "      <th>rsi_28</th>\n",
       "      <th>wr_14</th>\n",
       "      <th>wr_28</th>\n",
       "      <th>wr_50</th>\n",
       "      <th>wr_100</th>\n",
       "      <th>cci_14</th>\n",
       "      <th>cci_50</th>\n",
       "      <th>cci_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>108.099998</td>\n",
       "      <td>-15.050004</td>\n",
       "      <td>-42.129998</td>\n",
       "      <td>-59.720009</td>\n",
       "      <td>4.914073</td>\n",
       "      <td>14.937545</td>\n",
       "      <td>114.981999</td>\n",
       "      <td>117.373737</td>\n",
       "      <td>124.865000</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.840796</td>\n",
       "      <td>24.858748</td>\n",
       "      <td>29.590894</td>\n",
       "      <td>-95.085927</td>\n",
       "      <td>-96.330082</td>\n",
       "      <td>-97.393794</td>\n",
       "      <td>-98.352591</td>\n",
       "      <td>-99.789674</td>\n",
       "      <td>-177.989902</td>\n",
       "      <td>-156.887648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>113.639999</td>\n",
       "      <td>4.540001</td>\n",
       "      <td>-36.229996</td>\n",
       "      <td>-47.309998</td>\n",
       "      <td>15.795017</td>\n",
       "      <td>14.106850</td>\n",
       "      <td>115.889999</td>\n",
       "      <td>116.129158</td>\n",
       "      <td>121.242000</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.628578</td>\n",
       "      <td>29.497492</td>\n",
       "      <td>31.807717</td>\n",
       "      <td>-84.204983</td>\n",
       "      <td>-90.453967</td>\n",
       "      <td>-93.220849</td>\n",
       "      <td>-95.714830</td>\n",
       "      <td>-83.811858</td>\n",
       "      <td>-162.262414</td>\n",
       "      <td>-151.696454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>110.339996</td>\n",
       "      <td>-2.370003</td>\n",
       "      <td>-27.460007</td>\n",
       "      <td>-46.460007</td>\n",
       "      <td>10.115344</td>\n",
       "      <td>10.274811</td>\n",
       "      <td>115.415999</td>\n",
       "      <td>114.199437</td>\n",
       "      <td>118.496000</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.501870</td>\n",
       "      <td>28.373846</td>\n",
       "      <td>31.200886</td>\n",
       "      <td>-89.884656</td>\n",
       "      <td>-93.954182</td>\n",
       "      <td>-95.706540</td>\n",
       "      <td>-97.286060</td>\n",
       "      <td>-85.527537</td>\n",
       "      <td>-156.566429</td>\n",
       "      <td>-151.403135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>113.059998</td>\n",
       "      <td>-8.760002</td>\n",
       "      <td>-24.510009</td>\n",
       "      <td>-44.610000</td>\n",
       "      <td>19.009798</td>\n",
       "      <td>14.973386</td>\n",
       "      <td>113.663998</td>\n",
       "      <td>113.819624</td>\n",
       "      <td>116.044999</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.963374</td>\n",
       "      <td>30.716529</td>\n",
       "      <td>32.304817</td>\n",
       "      <td>-80.990202</td>\n",
       "      <td>-88.415199</td>\n",
       "      <td>-91.702928</td>\n",
       "      <td>-94.714753</td>\n",
       "      <td>-79.395973</td>\n",
       "      <td>-147.167398</td>\n",
       "      <td>-148.471900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>119.769997</td>\n",
       "      <td>-3.410003</td>\n",
       "      <td>-5.580001</td>\n",
       "      <td>-30.459999</td>\n",
       "      <td>33.607781</td>\n",
       "      <td>20.910975</td>\n",
       "      <td>112.981998</td>\n",
       "      <td>115.803082</td>\n",
       "      <td>115.486999</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.790098</td>\n",
       "      <td>36.255423</td>\n",
       "      <td>34.974092</td>\n",
       "      <td>-66.392219</td>\n",
       "      <td>-81.505510</td>\n",
       "      <td>-86.754186</td>\n",
       "      <td>-91.527902</td>\n",
       "      <td>-14.502006</td>\n",
       "      <td>-116.171395</td>\n",
       "      <td>-131.961966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>172.979996</td>\n",
       "      <td>-2.240005</td>\n",
       "      <td>2.149994</td>\n",
       "      <td>-0.820007</td>\n",
       "      <td>52.527373</td>\n",
       "      <td>38.360227</td>\n",
       "      <td>168.800000</td>\n",
       "      <td>170.389560</td>\n",
       "      <td>172.514000</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.469799</td>\n",
       "      <td>46.609577</td>\n",
       "      <td>43.644649</td>\n",
       "      <td>-47.472627</td>\n",
       "      <td>-72.158967</td>\n",
       "      <td>-72.344205</td>\n",
       "      <td>-88.080673</td>\n",
       "      <td>-10.987316</td>\n",
       "      <td>-77.255762</td>\n",
       "      <td>-92.739927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>176.880005</td>\n",
       "      <td>10.250000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>5.559998</td>\n",
       "      <td>68.955377</td>\n",
       "      <td>46.658246</td>\n",
       "      <td>170.850000</td>\n",
       "      <td>172.553042</td>\n",
       "      <td>172.939000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.740549</td>\n",
       "      <td>50.125470</td>\n",
       "      <td>45.499575</td>\n",
       "      <td>-31.044623</td>\n",
       "      <td>-63.435317</td>\n",
       "      <td>-63.694819</td>\n",
       "      <td>-84.352888</td>\n",
       "      <td>60.289544</td>\n",
       "      <td>-46.134807</td>\n",
       "      <td>-80.637997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>2024-04-10</td>\n",
       "      <td>171.759995</td>\n",
       "      <td>3.379990</td>\n",
       "      <td>-5.910003</td>\n",
       "      <td>-3.900009</td>\n",
       "      <td>47.388364</td>\n",
       "      <td>56.290371</td>\n",
       "      <td>171.525998</td>\n",
       "      <td>172.288693</td>\n",
       "      <td>172.348000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.535005</td>\n",
       "      <td>45.856141</td>\n",
       "      <td>43.548113</td>\n",
       "      <td>-52.611636</td>\n",
       "      <td>-74.437633</td>\n",
       "      <td>-75.049906</td>\n",
       "      <td>-89.246799</td>\n",
       "      <td>-6.560040</td>\n",
       "      <td>-69.304516</td>\n",
       "      <td>-88.062685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>2024-04-11</td>\n",
       "      <td>174.600006</td>\n",
       "      <td>3.490005</td>\n",
       "      <td>-5.229996</td>\n",
       "      <td>1.779999</td>\n",
       "      <td>59.351340</td>\n",
       "      <td>58.565027</td>\n",
       "      <td>172.223999</td>\n",
       "      <td>173.059131</td>\n",
       "      <td>171.825000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.107128</td>\n",
       "      <td>48.477531</td>\n",
       "      <td>44.907334</td>\n",
       "      <td>-40.648660</td>\n",
       "      <td>-64.092739</td>\n",
       "      <td>-68.751369</td>\n",
       "      <td>-86.532203</td>\n",
       "      <td>9.834233</td>\n",
       "      <td>-61.828807</td>\n",
       "      <td>-84.642709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>2024-04-12</td>\n",
       "      <td>171.050003</td>\n",
       "      <td>6.150009</td>\n",
       "      <td>-4.739990</td>\n",
       "      <td>0.220001</td>\n",
       "      <td>44.397665</td>\n",
       "      <td>50.379123</td>\n",
       "      <td>173.454001</td>\n",
       "      <td>172.389421</td>\n",
       "      <td>171.351001</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.019679</td>\n",
       "      <td>45.511363</td>\n",
       "      <td>43.548132</td>\n",
       "      <td>-55.602335</td>\n",
       "      <td>-56.229204</td>\n",
       "      <td>-76.624517</td>\n",
       "      <td>-89.925438</td>\n",
       "      <td>-18.526388</td>\n",
       "      <td>-68.014469</td>\n",
       "      <td>-86.079047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>321 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date       Close      MOM_5     MOM_10     MOM_14       STCK  \\\n",
       "1259  2023-01-03  108.099998 -15.050004 -42.129998 -59.720009   4.914073   \n",
       "1260  2023-01-04  113.639999   4.540001 -36.229996 -47.309998  15.795017   \n",
       "1261  2023-01-05  110.339996  -2.370003 -27.460007 -46.460007  10.115344   \n",
       "1262  2023-01-06  113.059998  -8.760002 -24.510009 -44.610000  19.009798   \n",
       "1263  2023-01-09  119.769997  -3.410003  -5.580001 -30.459999  33.607781   \n",
       "...          ...         ...        ...        ...        ...        ...   \n",
       "1575  2024-04-08  172.979996  -2.240005   2.149994  -0.820007  52.527373   \n",
       "1576  2024-04-09  176.880005  10.250000   4.250000   5.559998  68.955377   \n",
       "1577  2024-04-10  171.759995   3.379990  -5.910003  -3.900009  47.388364   \n",
       "1578  2024-04-11  174.600006   3.490005  -5.229996   1.779999  59.351340   \n",
       "1579  2024-04-12  171.050003   6.150009  -4.739990   0.220001  44.397665   \n",
       "\n",
       "           STCD  close_5_sma  close_5_ema  close_10_sma  ...  macd_45_25_15  \\\n",
       "1259  14.937545   114.981999   117.373737    124.865000  ...     -19.840796   \n",
       "1260  14.106850   115.889999   116.129158    121.242000  ...     -19.628578   \n",
       "1261  10.274811   115.415999   114.199437    118.496000  ...     -19.501870   \n",
       "1262  14.973386   113.663998   113.819624    116.044999  ...     -18.963374   \n",
       "1263  20.910975   112.981998   115.803082    115.486999  ...     -17.790098   \n",
       "...         ...          ...          ...           ...  ...            ...   \n",
       "1575  38.360227   168.800000   170.389560    172.514000  ...      -4.469799   \n",
       "1576  46.658246   170.850000   172.553042    172.939000  ...      -3.740549   \n",
       "1577  56.290371   171.525998   172.288693    172.348000  ...      -3.535005   \n",
       "1578  58.565027   172.223999   173.059131    171.825000  ...      -3.107128   \n",
       "1579  50.379123   173.454001   172.389421    171.351001  ...      -3.019679   \n",
       "\n",
       "         rsi_14     rsi_28      wr_14      wr_28      wr_50     wr_100  \\\n",
       "1259  24.858748  29.590894 -95.085927 -96.330082 -97.393794 -98.352591   \n",
       "1260  29.497492  31.807717 -84.204983 -90.453967 -93.220849 -95.714830   \n",
       "1261  28.373846  31.200886 -89.884656 -93.954182 -95.706540 -97.286060   \n",
       "1262  30.716529  32.304817 -80.990202 -88.415199 -91.702928 -94.714753   \n",
       "1263  36.255423  34.974092 -66.392219 -81.505510 -86.754186 -91.527902   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1575  46.609577  43.644649 -47.472627 -72.158967 -72.344205 -88.080673   \n",
       "1576  50.125470  45.499575 -31.044623 -63.435317 -63.694819 -84.352888   \n",
       "1577  45.856141  43.548113 -52.611636 -74.437633 -75.049906 -89.246799   \n",
       "1578  48.477531  44.907334 -40.648660 -64.092739 -68.751369 -86.532203   \n",
       "1579  45.511363  43.548132 -55.602335 -56.229204 -76.624517 -89.925438   \n",
       "\n",
       "         cci_14      cci_50     cci_100  \n",
       "1259 -99.789674 -177.989902 -156.887648  \n",
       "1260 -83.811858 -162.262414 -151.696454  \n",
       "1261 -85.527537 -156.566429 -151.403135  \n",
       "1262 -79.395973 -147.167398 -148.471900  \n",
       "1263 -14.502006 -116.171395 -131.961966  \n",
       "...         ...         ...         ...  \n",
       "1575 -10.987316  -77.255762  -92.739927  \n",
       "1576  60.289544  -46.134807  -80.637997  \n",
       "1577  -6.560040  -69.304516  -88.062685  \n",
       "1578   9.834233  -61.828807  -84.642709  \n",
       "1579 -18.526388  -68.014469  -86.079047  \n",
       "\n",
       "[321 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = data1[1259:1580]\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c640d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[113.639999],\n",
       "       [110.339996],\n",
       "       [113.059998],\n",
       "       [119.769997],\n",
       "       [118.849998],\n",
       "       [123.220001],\n",
       "       [123.559998],\n",
       "       [122.400002],\n",
       "       [131.490005],\n",
       "       [128.779999],\n",
       "       [127.169998],\n",
       "       [133.419998],\n",
       "       [143.75    ],\n",
       "       [143.889999],\n",
       "       [144.429993],\n",
       "       [160.270004],\n",
       "       [177.899994],\n",
       "       [166.660004],\n",
       "       [173.220001],\n",
       "       [181.410004],\n",
       "       [188.270004],\n",
       "       [189.979996],\n",
       "       [194.759995],\n",
       "       [196.809998],\n",
       "       [201.289993],\n",
       "       [207.320007],\n",
       "       [196.889999],\n",
       "       [194.639999],\n",
       "       [209.25    ],\n",
       "       [214.240005],\n",
       "       [202.039993],\n",
       "       [208.309998],\n",
       "       [197.369995],\n",
       "       [200.860001],\n",
       "       [202.070007],\n",
       "       [196.880005],\n",
       "       [207.630005],\n",
       "       [205.710007],\n",
       "       [202.770004],\n",
       "       [190.899994],\n",
       "       [197.789993],\n",
       "       [193.809998],\n",
       "       [187.710007],\n",
       "       [182.      ],\n",
       "       [172.919998],\n",
       "       [173.440002],\n",
       "       [174.479996],\n",
       "       [183.259995],\n",
       "       [180.449997],\n",
       "       [184.130005],\n",
       "       [180.130005],\n",
       "       [183.25    ],\n",
       "       [197.580002],\n",
       "       [191.149994],\n",
       "       [192.220001],\n",
       "       [190.410004],\n",
       "       [191.809998],\n",
       "       [189.190002],\n",
       "       [193.880005],\n",
       "       [195.279999],\n",
       "       [207.460007],\n",
       "       [194.770004],\n",
       "       [192.580002],\n",
       "       [185.520004],\n",
       "       [185.059998],\n",
       "       [184.509995],\n",
       "       [186.789993],\n",
       "       [180.539993],\n",
       "       [185.899994],\n",
       "       [185.      ],\n",
       "       [187.039993],\n",
       "       [184.309998],\n",
       "       [180.589996],\n",
       "       [162.990005],\n",
       "       [165.080002],\n",
       "       [162.550003],\n",
       "       [160.669998],\n",
       "       [153.75    ],\n",
       "       [160.190002],\n",
       "       [164.309998],\n",
       "       [161.830002],\n",
       "       [160.309998],\n",
       "       [160.610001],\n",
       "       [161.199997],\n",
       "       [170.059998],\n",
       "       [171.789993],\n",
       "       [169.149994],\n",
       "       [168.539993],\n",
       "       [172.080002],\n",
       "       [167.979996],\n",
       "       [166.350006],\n",
       "       [166.520004],\n",
       "       [173.860001],\n",
       "       [176.889999],\n",
       "       [180.139999],\n",
       "       [188.869995],\n",
       "       [185.770004],\n",
       "       [182.899994],\n",
       "       [184.470001],\n",
       "       [193.169998],\n",
       "       [201.160004],\n",
       "       [203.929993],\n",
       "       [207.520004],\n",
       "       [213.970001],\n",
       "       [217.610001],\n",
       "       [221.309998],\n",
       "       [224.570007],\n",
       "       [234.860001],\n",
       "       [244.399994],\n",
       "       [249.830002],\n",
       "       [258.709991],\n",
       "       [256.790009],\n",
       "       [255.899994],\n",
       "       [260.540009],\n",
       "       [274.450012],\n",
       "       [259.459991],\n",
       "       [264.609985],\n",
       "       [256.600006],\n",
       "       [241.050003],\n",
       "       [250.210007],\n",
       "       [256.23999 ],\n",
       "       [257.5     ],\n",
       "       [261.769989],\n",
       "       [279.820007],\n",
       "       [282.480011],\n",
       "       [276.540009],\n",
       "       [274.429993],\n",
       "       [269.609985],\n",
       "       [269.790009],\n",
       "       [271.98999 ],\n",
       "       [277.899994],\n",
       "       [281.380005],\n",
       "       [290.380005],\n",
       "       [293.339996],\n",
       "       [291.26001 ],\n",
       "       [262.899994],\n",
       "       [260.019989],\n",
       "       [269.059998],\n",
       "       [265.279999],\n",
       "       [264.350006],\n",
       "       [255.710007],\n",
       "       [266.440002],\n",
       "       [267.429993],\n",
       "       [261.070007],\n",
       "       [254.110001],\n",
       "       [259.320007],\n",
       "       [253.860001],\n",
       "       [251.449997],\n",
       "       [249.699997],\n",
       "       [242.190002],\n",
       "       [245.339996],\n",
       "       [242.649994],\n",
       "       [239.759995],\n",
       "       [232.960007],\n",
       "       [225.600006],\n",
       "       [219.220001],\n",
       "       [215.490005],\n",
       "       [231.279999],\n",
       "       [233.190002],\n",
       "       [236.860001],\n",
       "       [230.039993],\n",
       "       [238.589996],\n",
       "       [238.820007],\n",
       "       [257.179993],\n",
       "       [256.899994],\n",
       "       [258.079987],\n",
       "       [245.009995],\n",
       "       [256.48999 ],\n",
       "       [251.919998],\n",
       "       [251.490005],\n",
       "       [248.5     ],\n",
       "       [273.579987],\n",
       "       [267.480011],\n",
       "       [271.299988],\n",
       "       [276.040009],\n",
       "       [274.390015],\n",
       "       [265.279999],\n",
       "       [266.5     ],\n",
       "       [262.589996],\n",
       "       [255.699997],\n",
       "       [244.880005],\n",
       "       [246.990005],\n",
       "       [244.119995],\n",
       "       [240.5     ],\n",
       "       [246.380005],\n",
       "       [250.220001],\n",
       "       [251.600006],\n",
       "       [246.529999],\n",
       "       [261.160004],\n",
       "       [260.049988],\n",
       "       [260.529999],\n",
       "       [259.670013],\n",
       "       [263.619995],\n",
       "       [262.98999 ],\n",
       "       [258.869995],\n",
       "       [251.119995],\n",
       "       [253.919998],\n",
       "       [254.850006],\n",
       "       [242.679993],\n",
       "       [220.110001],\n",
       "       [211.990005],\n",
       "       [212.080002],\n",
       "       [216.520004],\n",
       "       [212.419998],\n",
       "       [205.759995],\n",
       "       [207.300003],\n",
       "       [197.360001],\n",
       "       [200.839996],\n",
       "       [205.660004],\n",
       "       [218.509995],\n",
       "       [219.960007],\n",
       "       [219.270004],\n",
       "       [222.179993],\n",
       "       [222.110001],\n",
       "       [209.979996],\n",
       "       [214.649994],\n",
       "       [223.710007],\n",
       "       [237.410004],\n",
       "       [242.839996],\n",
       "       [233.589996],\n",
       "       [234.300003],\n",
       "       [235.600006],\n",
       "       [241.199997],\n",
       "       [234.210007],\n",
       "       [235.449997],\n",
       "       [236.080002],\n",
       "       [246.720001],\n",
       "       [244.139999],\n",
       "       [240.080002],\n",
       "       [238.830002],\n",
       "       [235.580002],\n",
       "       [238.720001],\n",
       "       [239.369995],\n",
       "       [242.639999],\n",
       "       [243.839996],\n",
       "       [239.740005],\n",
       "       [237.009995],\n",
       "       [239.289993],\n",
       "       [251.050003],\n",
       "       [253.5     ],\n",
       "       [252.080002],\n",
       "       [257.220001],\n",
       "       [247.139999],\n",
       "       [254.5     ],\n",
       "       [252.539993],\n",
       "       [256.609985],\n",
       "       [261.440002],\n",
       "       [253.179993],\n",
       "       [248.479996],\n",
       "       [248.419998],\n",
       "       [238.449997],\n",
       "       [237.929993],\n",
       "       [237.490005],\n",
       "       [240.449997],\n",
       "       [234.960007],\n",
       "       [233.940002],\n",
       "       [227.220001],\n",
       "       [218.889999],\n",
       "       [219.910004],\n",
       "       [215.550003],\n",
       "       [211.880005],\n",
       "       [212.190002],\n",
       "       [208.800003],\n",
       "       [209.139999],\n",
       "       [207.830002],\n",
       "       [182.630005],\n",
       "       [183.25    ],\n",
       "       [190.929993],\n",
       "       [191.589996],\n",
       "       [187.289993],\n",
       "       [188.860001],\n",
       "       [187.910004],\n",
       "       [181.059998],\n",
       "       [185.100006],\n",
       "       [187.580002],\n",
       "       [189.559998],\n",
       "       [193.570007],\n",
       "       [188.130005],\n",
       "       [184.020004],\n",
       "       [188.710007],\n",
       "       [200.449997],\n",
       "       [199.949997],\n",
       "       [193.759995],\n",
       "       [194.770004],\n",
       "       [197.410004],\n",
       "       [191.970001],\n",
       "       [199.399994],\n",
       "       [199.729996],\n",
       "       [202.039993],\n",
       "       [201.880005],\n",
       "       [202.639999],\n",
       "       [188.139999],\n",
       "       [180.740005],\n",
       "       [176.539993],\n",
       "       [178.649994],\n",
       "       [175.339996],\n",
       "       [177.770004],\n",
       "       [177.539993],\n",
       "       [169.479996],\n",
       "       [162.5     ],\n",
       "       [163.570007],\n",
       "       [173.800003],\n",
       "       [171.320007],\n",
       "       [175.660004],\n",
       "       [172.820007],\n",
       "       [170.830002],\n",
       "       [172.630005],\n",
       "       [177.669998],\n",
       "       [179.830002],\n",
       "       [175.789993],\n",
       "       [175.220001],\n",
       "       [166.630005],\n",
       "       [168.380005],\n",
       "       [171.110001],\n",
       "       [164.899994],\n",
       "       [172.979996],\n",
       "       [176.880005],\n",
       "       [171.759995],\n",
       "       [174.600006],\n",
       "       [171.050003],\n",
       "       [161.479996]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = Data_intergate(data1['Close'][1259:1581], next_days)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef4b500b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0b0c87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features:  32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train.to_csv('./FE results/Train_original.csv')\n",
    "Train_date = X_train['Date']\n",
    "X_train = X_train.drop(columns=['Date'])\n",
    "\n",
    "\n",
    "X_test.to_csv('./FE results/Test_original.csv')\n",
    "Test_date = X_test['Date']\n",
    "X_test = X_test.drop(columns=['Date'])\n",
    "\n",
    "y_train = DataFrame(y_train)\n",
    "y_train.to_csv('./FE results/y_train.csv')\n",
    "y_test = DataFrame(y_test)\n",
    "y_test.to_csv('./FE results/y_test.csv')\n",
    "print('Original number of features: ', data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9109fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######Boruta######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of features after Boruta:  22\n",
      "Remained Feature:\n",
      "['Close' 'MOM_10' 'MOM_14' 'close_5_sma' 'close_5_ema' 'close_10_sma'\n",
      " 'close_10_ema' 'close_14_sma' 'close_14_ema' 'close_30_sma'\n",
      " 'close_30_ema' 'close_50_sma' 'close_50_ema' 'close_100_sma'\n",
      " 'close_100_ema' 'close_200_sma' 'close_200_ema' 'rsi_28' 'wr_14' 'wr_100'\n",
      " 'cci_14' 'cci_100']\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "# Boruta\n",
    "print('######Boruta######')\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from boruta import BorutaPy\n",
    "rf = RandomForestRegressor(n_jobs=-1, max_depth=5)\n",
    "feat_selector = BorutaPy(rf, n_estimators='auto')\n",
    "X_train_boruta = feat_selector.fit_transform(X_train.values, y_train.values)\n",
    "X_test_boruta = feat_selector.transform(X_test.values)\n",
    "print('The number of features after Boruta: ', np.sum(feat_selector.support_==True))\n",
    "print('Remained Feature:')\n",
    "print(X_train.columns[feat_selector.support_].values)\n",
    "Train_boruta = DataFrame(X_train_boruta)\n",
    "Train_boruta.insert(0, 'Date', Train_date.values)\n",
    "Test_boruta = DataFrame(X_test_boruta)\n",
    "Test_boruta.insert(0, 'Date', Test_date.values)\n",
    "Train_boruta.to_csv('./FE results/Train_boruta.csv')\n",
    "Test_boruta.to_csv('./FE results/Test_boruta.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f8d83b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########PCA#########\n",
      "The number of features after PCA:  5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Cumulative Variance Ratio  Explained Variance Ratio\n",
      "0                   0.476350                  0.476350\n",
      "1                   0.832800                  0.356449\n",
      "2                   0.892951                  0.060151\n",
      "3                   0.940422                  0.047471\n",
      "4                   0.956977                  0.016556\n",
      "#########t-SNE#########\n",
      "The number of features after t-SNE:  3\n",
      "KL divergence:  0.19278894364833832\n"
     ]
    }
   ],
   "source": [
    "# PCA\n",
    "print(\"#########PCA#########\")\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.fit_transform(X_test)\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "print('The number of features after PCA: ', pca.n_components_)\n",
    "Train_pca = DataFrame(X_train_pca)\n",
    "Train_pca.insert(0, 'Date', Train_date.values)\n",
    "Test_pca = DataFrame(X_test_pca)\n",
    "Test_pca.insert(0, 'Date', Test_date.values)\n",
    "Train_pca.to_csv('./FE results/Train_pca.csv')\n",
    "Test_pca.to_csv('./FE results/Test_pca.csv')\n",
    "# plot\n",
    "pca_all = PCA(n_components=31)\n",
    "pca_all.fit(X_train_scaled)\n",
    "evr = pca_all.explained_variance_ratio_\n",
    "cvr = np.cumsum(evr)\n",
    "sns.set(style='whitegrid')\n",
    "plt.plot(cvr)\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.axvline(linewidth=4, color='r', linestyle='--', x=pca.n_components_, ymin=0, ymax=1)\n",
    "plt.show()\n",
    "pca_df = pd.DataFrame()\n",
    "pca_df['Cumulative Variance Ratio'] = cvr\n",
    "pca_df['Explained Variance Ratio'] = evr\n",
    "print(pca_df.head(pca.n_components_))\n",
    "\n",
    "# t-SNE\n",
    "print(\"#########t-SNE#########\")\n",
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=3)\n",
    "X_train_tsne = tsne.fit_transform(X_train)\n",
    "X_test_tsne = tsne.fit_transform(X_test)\n",
    "print('The number of features after t-SNE: ', X_train_tsne.shape[1])\n",
    "print('KL divergence: ', tsne.kl_divergence_)\n",
    "Train_tsne = DataFrame(X_train_tsne)\n",
    "Train_tsne.insert(0, 'Date', Train_date.values)\n",
    "Test_tsne = DataFrame(X_test_tsne)\n",
    "Test_tsne.insert(0, 'Date', Test_date.values)\n",
    "Train_tsne.to_csv('./FE results/Train_tsne.csv')\n",
    "Test_tsne.to_csv('./FE results/Test_tsne.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b13558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
