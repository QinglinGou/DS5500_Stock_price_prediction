{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y832op1GPzFj",
        "outputId": "369706a4-3dad-4cfa-9710-664c45e1aee7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikeras in /Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages (0.12.0)\n",
            "Requirement already satisfied: packaging>=0.21 in /Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages (from scikeras) (23.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages (from scikeras) (1.3.1)\n",
            "Requirement already satisfied: tensorflow-metal<2.0.0,>=1.1.0 in /Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages (from scikeras) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages (from scikit-learn>=1.0.0->scikeras) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages (from scikit-learn>=1.0.0->scikeras) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages (from scikit-learn>=1.0.0->scikeras) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages (from scikit-learn>=1.0.0->scikeras) (3.2.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages (from tensorflow-metal<2.0.0,>=1.1.0->scikeras) (0.41.2)\n",
            "Requirement already satisfied: six>=1.15.0 in /Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages (from tensorflow-metal<2.0.0,>=1.1.0->scikeras) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install scikeras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsxQ7NmCP22o",
        "outputId": "beb75e24-885e-455d-b5ae-c3aee7386b12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optuna in /Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages (3.5.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages (from optuna) (1.13.1)\n",
            "Requirement already satisfied: colorlog in /Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages (from optuna) (6.8.2)\n",
            "Requirement already satisfied: numpy in /Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages (from optuna) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages (from optuna) (23.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages (from optuna) (2.0.28)\n",
            "Requirement already satisfied: tqdm in /Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages (from optuna) (4.66.1)\n",
            "Requirement already satisfied: PyYAML in /Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages (from optuna) (6.0.1)\n",
            "Requirement already satisfied: Mako in /Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4 in /Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.7.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /Users/qinglingou/anaconda3/envs/pytorch-gpu/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VCKCjHpdP3YQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas import DataFrame\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.model_selection import cross_val_score, TimeSeriesSplit\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from scikeras.wrappers import KerasRegressor\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
        "\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import optuna\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nFiYYEvtVwtQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PJBXBIUXVw12"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bPSBnescQTDG"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "# Pre-Loading\n",
        "y_train = pd.read_csv(\"FE results/y_train.csv\")\n",
        "y_train = y_train.drop(columns=['Unnamed: 0'])\n",
        "y_test = pd.read_csv(\"FE results/y_test.csv\")\n",
        "y_test = y_test.drop(columns=['Unnamed: 0'])\n",
        "\n",
        "\n",
        "# Load Data\n",
        "X_train = pd.read_csv(\"FE results/Train_original.csv\")\n",
        "Train_date = X_train['Date']\n",
        "X_train = X_train.drop(columns=['Unnamed: 0', 'Date'])\n",
        "X_test = pd.read_csv(\"FE results/Test_original.csv\")\n",
        "Test_date = X_test['Date']\n",
        "X_test = X_test.drop(columns=['Unnamed: 0', 'Date'])\n",
        "\n",
        "# Initialize scaler\n",
        "scaler_x = MinMaxScaler(feature_range=(0, 1))\n",
        "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "# Normalize features\n",
        "X_train_scaled = scaler_x.fit_transform(X_train)\n",
        "X_test_scaled = scaler_x.transform(X_test)\n",
        "\n",
        "# Assuming y_train and y_test are single columns and not DataFrames at this point\n",
        "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))\n",
        "\n",
        "def create_sequences(input_data, target_data, n_steps):\n",
        "    X, y = [], []\n",
        "    for i in range(len(input_data) - n_steps):\n",
        "        X.append(input_data[i:i+n_steps])\n",
        "        y.append(target_data[i+n_steps, 0])  # Assuming target_data is the column vector\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "n_steps = 7  # Define the number of steps in your sequence\n",
        "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, n_steps)\n",
        "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_scaled, n_steps)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bKuzj3XSWAje"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "h1R12f35ArbU"
      },
      "outputs": [],
      "source": [
        "def create_lstm_model(input_shape, optimizer='adam', lstm_units=50, dropout_rate=0.2, l2_regularization=0.01):\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(units=lstm_units, return_sequences=True), input_shape=input_shape))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(LSTM(units=lstm_units))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1, kernel_regularizer=l2(l2_regularization)))\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "# Assuming create_lstm_model and create_sequences are already defined\n",
        "\n",
        "def run_optuna_optimization(X_train, y_train, X_test, y_test, n_steps, n_trials=5):\n",
        "    def lstm_objective(trial):\n",
        "        # Initialize scalers\n",
        "        scaler_x = MinMaxScaler(feature_range=(0, 1))\n",
        "        scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "        # Normalize features and targets\n",
        "        X_train_scaled = scaler_x.fit_transform(X_train)\n",
        "        X_test_scaled = scaler_x.transform(X_test)\n",
        "        y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1))\n",
        "        y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1))\n",
        "\n",
        "        # Create sequences\n",
        "        X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, n_steps)\n",
        "        X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_scaled, n_steps)\n",
        "\n",
        "        # Hyperparameters\n",
        "\n",
        "        lstm_units = trial.suggest_categorical('lstm_units', [50, 100])\n",
        "        dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.2)\n",
        "        learning_rate = trial.suggest_float('learning_rate', 0.001, 0.01, log=True)\n",
        "\n",
        "\n",
        "        # Model definition\n",
        "        model = create_lstm_model(input_shape=(n_steps, X_train_seq.shape[2]),\n",
        "                                  lstm_units=lstm_units,\n",
        "                                  dropout_rate=dropout_rate,\n",
        "                                  optimizer=Adam(learning_rate=learning_rate))\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train_seq, y_train_seq, epochs=100, batch_size=64, validation_split=0.2, verbose=0)\n",
        "\n",
        "        # Evaluate\n",
        "        train_pred_scaled = model.predict(X_train_seq)\n",
        "        test_pred_scaled = model.predict(X_test_seq)\n",
        "        train_pred = scaler_y.inverse_transform(train_pred_scaled)\n",
        "        test_pred = scaler_y.inverse_transform(test_pred_scaled)\n",
        "\n",
        "        # Metrics\n",
        "        train_mae = mean_absolute_error(y_train[n_steps:], train_pred)\n",
        "        train_rmse = np.sqrt(mean_squared_error(y_train[n_steps:], train_pred))\n",
        "        test_mae = mean_absolute_error(y_test[n_steps:], test_pred)\n",
        "        test_rmse = np.sqrt(mean_squared_error(y_test[n_steps:], test_pred))\n",
        "\n",
        "        trial.set_user_attr('train_mae', train_mae)\n",
        "        trial.set_user_attr('train_rmse', train_rmse)\n",
        "        trial.set_user_attr('test_mae', test_mae)\n",
        "        trial.set_user_attr('test_rmse', test_rmse)\n",
        "\n",
        "        return test_rmse\n",
        "\n",
        "    study = optuna.create_study(direction='minimize')\n",
        "    study.optimize(lstm_objective, n_trials=n_trials)\n",
        "\n",
        "    best_trial = study.best_trial\n",
        "\n",
        "    # Re-train the best model to get predictions for visualization\n",
        "    best_params = best_trial.params\n",
        "    model = create_lstm_model(\n",
        "        input_shape=(n_steps, X_train_seq.shape[2]),\n",
        "        lstm_units=best_params['lstm_units'],\n",
        "        dropout_rate=best_params['dropout_rate'],\n",
        "        optimizer=Adam(learning_rate=best_params['learning_rate'])\n",
        "     )\n",
        "    model.fit(X_train_seq, y_train_seq, epochs=100, batch_size=64, validation_split=0.2, verbose=0)\n",
        "\n",
        "    # Predict with the best model\n",
        "    #train_pred = scaler_y.inverse_transform(model.predict(X_train_seq))\n",
        "    #test_pred = scaler_y.inverse_transform(model.predict(X_test_seq))\n",
        "    #pred_list = {'train_pred': train_pred, 'test_pred': test_pred}\n",
        "\n",
        "    #results = {\n",
        "        #'Feature Engineering Method': 'Method Name',  # This will be replaced by the actual method name later\n",
        "        #'Best Trial Train MAE': best_trial.user_attrs['train_mae'],\n",
        "       # 'Best Trial Train RMSE': best_trial.user_attrs['train_rmse'],\n",
        "       # 'Best Trial Test MAE': best_trial.user_attrs['test_mae'],\n",
        "       # 'Best Trial Test RMSE': best_trial.user_attrs['test_rmse'],\n",
        "        #'Best Params': best_trial.params\n",
        "   #}\n",
        "\n",
        "\n",
        "   # After retraining the best model\n",
        "    train_pred = scaler_y.inverse_transform(model.predict(X_train_seq))\n",
        "    test_pred = scaler_y.inverse_transform(model.predict(X_test_seq))\n",
        "    pred_list = {'train_pred': train_pred, 'test_pred': test_pred}\n",
        "\n",
        "# Recalculate metrics for the retrained model\n",
        "    final_train_mae = mean_absolute_error(y_train[n_steps:], train_pred)\n",
        "    final_train_rmse = np.sqrt(mean_squared_error(y_train[n_steps:], train_pred))\n",
        "    final_test_mae = mean_absolute_error(y_test[n_steps:], test_pred)\n",
        "    final_test_rmse = np.sqrt(mean_squared_error(y_test[n_steps:], test_pred))\n",
        "\n",
        "# Update the results dictionary with the new metrics\n",
        "    results = {\n",
        "    'Feature Engineering Method': 'Method Name',  # Update with actual method name\n",
        "    'Best Trial Train MAE': final_train_mae,\n",
        "    'Best Trial Train RMSE': final_train_rmse,\n",
        "    'Best Trial Test MAE': final_test_mae,\n",
        "    'Best Trial Test RMSE': final_test_rmse,\n",
        "    'Best Params': best_trial.params\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "    return results, pred_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "q9a3udA-WApQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYGGaxkoArgY",
        "outputId": "44b9e326-4c0e-4a8f-bb65-08f737d175d2"
      },
      "outputs": [],
      "source": [
        "\n",
        "results_total = []\n",
        "predictions_total = {}\n",
        "# Placeholder for method names and corresponding data files\n",
        "fe_methods_data = {\n",
        "    'Without FE': ('./FE results/Train_original.csv', './FE results/Test_original.csv'),\n",
        "    'Boruta': ('./FE results/Train_boruta.csv', './FE results/Test_boruta.csv'),\n",
        "    'PCA': ('./FE results/Train_pca.csv', './FE results/Test_pca.csv'),\n",
        "    't-SNE': ('./FE results/Train_tsne.csv', './FE results/Test_tsne.csv'),\n",
        "}\n",
        "\n",
        "\n",
        "for method_name, (train_file, test_file) in fe_methods_data.items():\n",
        "    print(f'\\n####### {method_name} #######')\n",
        "    X_train = pd.read_csv(train_file).drop(columns=['Unnamed: 0', 'Date'])\n",
        "    y_train = pd.read_csv(\"FE results/y_train.csv\").drop(columns=['Unnamed: 0']).values.ravel()\n",
        "    X_test = pd.read_csv(test_file).drop(columns=['Unnamed: 0', 'Date'])\n",
        "    y_test = pd.read_csv(\"FE results/y_test.csv\").drop(columns=['Unnamed: 0']).values.ravel()\n",
        "\n",
        "    results, pred_list = run_optuna_optimization(X_train, y_train, X_test, y_test, n_steps, n_trials=10)\n",
        "    results['Feature Engineering Method'] = method_name  # Set the method name in the results\n",
        "\n",
        "    results_total.append(results)\n",
        "    predictions_total[method_name] = pred_list  # Store predictions by method\n",
        "\n",
        "# Convert results_total to DataFrame for easier analysis if needed\n",
        "results_df = pd.DataFrame(results_total)\n",
        "print(results_df)\n",
        "\n",
        "# Now, predictions_total contains the pred_list for each feature engineering method\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56_xk52OWAsH"
      },
      "outputs": [],
      "source": [
        "results_total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rz0pZ9teg8v"
      },
      "outputs": [],
      "source": [
        "predictions_total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KK9AFvmOuoBY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming y_actual is prepared outside this snippet as suggested.\n",
        "y_actual = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "plt.figure(figsize=(18, 10))\n",
        "\n",
        "for i, (method_name, pred_list) in enumerate(predictions_total.items(), start=1):\n",
        "    # Concatenate train and test predictions for continuity\n",
        "    predictions = np.concatenate((pred_list['train_pred'], pred_list['test_pred']), axis=0)\n",
        "\n",
        "    # Plot\n",
        "    plt.subplot(2, 2, i)\n",
        "    plt.plot(predictions, label=f'Predicted {method_name}', linestyle='--', marker='', color='red')\n",
        "    plt.plot(y_actual, label='Actual', linestyle='-', marker='', color='blue')\n",
        "    plt.title(f'{method_name}')\n",
        "    plt.xlabel('Time Step')\n",
        "    plt.ylabel('Value')\n",
        "    plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Feature Engineering Methods Comparison')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzJVVUH_WAuy"
      },
      "outputs": [],
      "source": [
        "results_total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSOwCCNyWAxn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMvjYkG3sbun"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Convert 'dates' to a Pandas DatetimeIndex for plotting if it's not already\n",
        "dates = np.concatenate((Train_date, Test_date), axis=0)\n",
        "y_actual = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "# Ensure dates is a datetime object for plotting\n",
        "dates = pd.to_datetime(dates)\n",
        "plt.rcParams[\"figure.figsize\"] = (20, 16)\n",
        "#plt.figure(figsize=(15, 8))  # Adjust the figure size as needed\n",
        "\n",
        "# Plot the actual values\n",
        "plt.plot(dates, y_actual, label='Actual')\n",
        "\n",
        "# Plot predictions from each feature engineering method\n",
        "colors = ['orange', 'green', 'red', 'purple']  # Different colors for each method\n",
        "for method, preds in predictions_total.items():\n",
        "    preds_combined = np.concatenate((preds['train_pred'].flatten(), preds['test_pred'].flatten()))\n",
        "    if preds_combined.shape[0] < dates.shape[0]:\n",
        "        # Pad predictions with NaNs for alignment\n",
        "        pad_length = dates.shape[0] - preds_combined.shape[0]\n",
        "        preds_combined = np.concatenate((np.full(pad_length, np.nan), preds_combined))\n",
        "\n",
        "    plt.plot(dates, preds_combined, label=f'Predicted {method}',color=colors.pop(0))\n",
        "\n",
        "# Mark the start of test data with a vertical line\n",
        "test_start_date = '2023-01-03'  # Replace with the actual start date of your test set\n",
        "plt.axvline(x=pd.to_datetime(test_start_date), color='red', linestyle='--', linewidth=2, label='Start of Test Data')\n",
        "\n",
        "# Finalize the plot\n",
        "plt.title('Comparison of Feature Engineering Methods')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Value')\n",
        "plt.legend()\n",
        "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))  # Format the x-axis with dates\n",
        "plt.gca().xaxis.set_major_locator(mdates.YearLocator())  # Set major ticks to yearly intervals\n",
        "plt.gcf().autofmt_xdate()  # Auto-format date labels\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDJaXdstX65-"
      },
      "outputs": [],
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (20, 16)\n",
        "axis_x = np.array(['2018-01-04', '2019-01-03', '2020-01-02', '2021-01-04', '2022-01-03', '2023-01-03','2024-01-25'])\n",
        "y_actual = np.concatenate((y_train, y_test), axis=0)\n",
        "dates = np.concatenate((Train_date, Test_date), axis=0)\n",
        "dates = pd.to_datetime(dates)\n",
        "plt.plot(dates, y_actual, label='Actual')\n",
        "\n",
        "# Plot predictions from each feature engineering method\n",
        "#colors = ['orange', 'green', 'red', 'purple']  # Different colors for each method\n",
        "for method, preds in predictions_total.items():\n",
        "    preds_combined = np.concatenate((preds['train_pred'].flatten(), preds['test_pred'].flatten()))\n",
        "    if preds_combined.shape[0] < dates.shape[0]:\n",
        "        # Pad predictions with NaNs for alignment\n",
        "        pad_length = dates.shape[0] - preds_combined.shape[0]\n",
        "        preds_combined = np.concatenate((np.full(pad_length, np.nan), preds_combined))\n",
        "\n",
        "   #plt.plot(dates, preds_combined, label=f'Predicted {method}',color=colors.pop(0))\n",
        "    plt.plot(dates, preds_combined, label=f'Predicted {method}')\n",
        "    plt.xticks(axis_x)\n",
        "\n",
        "# Mark the start of test data with a vertical line\n",
        "test_start_date = '2023-01-03'  # Replace with the actual start date of your test set\n",
        "plt.axvline(x=pd.to_datetime(test_start_date), color='red', linestyle='--', linewidth=2, label='Start of Test Data')\n",
        "# Adjust layout spacing to prevent labels and titles from overlapping\n",
        "plt.tight_layout(pad=3.0)\n",
        "plt.legend()\n",
        "# You can add a super title for the entire figure if you want\n",
        "plt.title('Comparison of Feature Engineering Methods')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U06AfGRIX68n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZf-FKlTX6_h"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQvzKxE9X7CU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kg349GCeX7E_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZpTzhf1X7IQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJx345Pfm_fx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRvN4zh8WA20"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "dates = np.concatenate((Train_date, Test_date), axis=0)\n",
        "y_actual = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "# Ensure dates is a datetime object for plotting\n",
        "dates = pd.to_datetime(dates)\n",
        "plt.rcParams[\"figure.figsize\"] = (20, 16)\n",
        "\n",
        "# Plot the actual values\n",
        "plt.plot(dates, y_actual, label='Actual')\n",
        "\n",
        "# Plot predictions from each feature engineering method\n",
        "colors = ['orange', 'green', 'red', 'purple']  # Different colors for each method\n",
        "for method, preds in predictions_total.items():\n",
        "    preds_combined = np.concatenate((preds['train_pred'].flatten(), preds['test_pred'].flatten()))\n",
        "    if preds_combined.shape[0] < dates.shape[0]:\n",
        "        # Pad predictions with NaNs for alignment\n",
        "        pad_length = dates.shape[0] - preds_combined.shape[0]\n",
        "        preds_combined = np.concatenate((np.full(pad_length, np.nan), preds_combined))\n",
        "\n",
        "    plt.plot(dates, preds_combined, label=f'Predicted {method}', color=colors.pop(0))\n",
        "\n",
        "# Mark the start of test data with a vertical line\n",
        "test_start_date = '2023-01-03'\n",
        "plt.axvline(x=pd.to_datetime(test_start_date), color='red', linestyle='--', linewidth=2, label='Start of Test Data')\n",
        "\n",
        "# Finalize the plot\n",
        "plt.title('Comparison of Feature Engineering Methods')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Value')\n",
        "plt.legend()\n",
        "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
        "plt.gca().xaxis.set_major_locator(mdates.YearLocator())\n",
        "\n",
        "# Set x-axis labels at a 45-degree angle\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zk0B1HbrSiYr"
      },
      "outputs": [],
      "source": [
        "test_total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mdsi0OZSibJ"
      },
      "outputs": [],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEr_oRhWSid1"
      },
      "outputs": [],
      "source": [
        "pred_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sazXn_nLTngu"
      },
      "outputs": [],
      "source": [
        "len(pred_list['test_pred'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_hq_Qf1Tnja"
      },
      "outputs": [],
      "source": [
        "len(pred_list['train_pred'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4XbXzIJTnl9"
      },
      "outputs": [],
      "source": [
        "len(y_train[7:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4aqpk6YTnoX"
      },
      "outputs": [],
      "source": [
        "len(y_test[7:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlyXUYVPTnrQ"
      },
      "outputs": [],
      "source": [
        "y_test[7:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXVs4Z_UUAQM"
      },
      "outputs": [],
      "source": [
        "pred_list['test_pred']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DE9sXGXaUAS5"
      },
      "outputs": [],
      "source": [
        "mean_absolute_error(y_test[7:],pred_list['test_pred'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_6A6ZNcSigU"
      },
      "outputs": [],
      "source": [
        "predictions_total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DPO_YBsSijC"
      },
      "outputs": [],
      "source": [
        "print(\"Inside function - Test MAE:\", test_mae)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtEDhlbPSilh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pytorch-gpu",
      "language": "python",
      "name": "pytorch-gpu"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
